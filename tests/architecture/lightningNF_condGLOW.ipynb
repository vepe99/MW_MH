{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import time\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightning as L\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:9\n"
     ]
    }
   ],
   "source": [
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = os.environ.get(\"PATH_CHECKPOINT\", \"saved_models/tutorial11\")\n",
    "\n",
    "# Setting the seed\n",
    "L.seed_everything(42)\n",
    "\n",
    "# Fetching the device that will be used throughout this notebook\n",
    "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:9\")\n",
    "print(\"Using device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFlow(L.LightningModule):\n",
    "    def __init__(self, n_layers, dim_notcond, dim_cond, import_samples=8, **kwargs_CL):\n",
    "        \"\"\"ImageFlow.\n",
    "\n",
    "        Args:\n",
    "            flows: A list of flows (each a nn.Module) that should be applied on the images.\n",
    "            import_samples: Number of importance samples to use during testing (see explanation below). Can be changed at any time\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.dim_notcond = dim_notcond\n",
    "        self.dim_cond = dim_cond\n",
    "        \n",
    "        coupling_layers = [CouplingLayer(dim_notcond, dim_cond, **kwargs_CL) for _ in range(n_layers)]\n",
    "        conv_layers = [GLOW_conv(dim_notcond) for _ in range(n_layers)]\n",
    "        \n",
    "        self.flows = nn.ModuleList(itertools.chain(*zip(conv_layers, coupling_layers)))\n",
    "        self.import_samples = import_samples\n",
    "        # Create prior distribution for final latent space\n",
    "        self.prior = torch.distributions.normal.Normal(loc=0.0, scale=1.0)\n",
    "        \n",
    "        kwargs_parsed = kwargs_CL.copy()\n",
    "        kwargs_parsed[\"network\"] = \"MLP\"\n",
    "        self.give_kwargs = {\"n_layers\":n_layers, \"dim_notcond\":dim_notcond, \"dim_cond\":dim_cond, \"CL\":\"AffineCoupling\", **kwargs_parsed}\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # The forward function is only used for visualizing the graph\n",
    "        return self._get_likelihood(x)\n",
    "\n",
    "    def encode(self, x):\n",
    "        # Given a batch of images, return the latent representation z and ldj of the transformations\n",
    "        z, ldj = x, torch.zeros(x.shape[0], device=self.device)\n",
    "        for flow in self.flows:\n",
    "            z, ldj = flow(z, x_condition, ldj, reverse=False)\n",
    "        return z, ldj\n",
    "    \n",
    "    def _get_likelihood(self, x, x_condition, return_ll=False):\n",
    "        \"\"\"Given a batch of images, return the likelihood of those.\n",
    "\n",
    "        If return_ll is True, this function returns the log likelihood of the input. Otherwise, the output metric is\n",
    "        bits per dimension (scaled negative log likelihood)\n",
    "        \"\"\"\n",
    "        z, ldj = self.encode(x, x_condition)\n",
    "        log_pz = self.prior.log_prob(z).sum()\n",
    "        log_px = ldj + log_pz\n",
    "        nll = -log_px\n",
    "        # Calculating bits per dimension\n",
    "        bpd = nll * np.log2(np.exp(1)) / np.prod(x.shape[1:])\n",
    "        return bpd.mean() if not return_ll else log_px\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def sample(self, x_condition, z_init=None):\n",
    "        \"\"\"Sample a batch of images from the flow.\"\"\"\n",
    "        # Sample latent representation from prior\n",
    "        if z_init is None:\n",
    "            z = self.prior.sample(sample_shape=self.dim_notcond).to(device)\n",
    "        else:\n",
    "            z = z_init.to(device)\n",
    "\n",
    "        # Transform z to x by inverting the flows\n",
    "        ldj = torch.zeros(self.dim_notocond, device=device)\n",
    "        for flow in reversed(self.flows):\n",
    "            z, ldj = flow(z, x_condition, ldj, reverse=True)\n",
    "        return z\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        # An scheduler is optional, but can help in flows to get the last bpd improvement\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.99)\n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Normalizing flows are trained by maximum likelihood => return bpd\n",
    "        loss = self._get_likelihood(batch[0, :2], batch[0, 2:])\n",
    "        self.log(\"train_bpd\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._get_likelihood(batch[0, :2], batch[0, 2:])\n",
    "        self.log(\"val_bpd\", loss)\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Perform importance sampling during testing => estimate likelihood M times for each image\n",
    "        samples = []\n",
    "        for _ in range(self.import_samples):\n",
    "            img_ll = self._get_likelihood(batch[0, :2], batch[0, 2:], return_ll=True)\n",
    "            samples.append(img_ll)\n",
    "        img_ll = torch.stack(samples, dim=-1)\n",
    "\n",
    "        # To average the probabilities, we need to go from log-space to exp, and back to log.\n",
    "        # Logsumexp provides us a stable implementation for this\n",
    "        img_ll = torch.logsumexp(img_ll, dim=-1) - np.log(self.import_samples)\n",
    "\n",
    "        # Calculate final bpd\n",
    "        bpd = -img_ll * np.log2(np.exp(1)) / np.prod(batch[0, 2:].shape[1:])\n",
    "        bpd = bpd.mean()\n",
    "\n",
    "        self.log(\"test_bpd\", bpd)\n",
    "        \n",
    "class CouplingLayer(nn.Module):\n",
    "    def __init__(self, dim_notcond, dim_cond, network=MLP, network_args=(16, 4, 0.2)):\n",
    "        \"\"\"Coupling layer inside a normalizing flow.\n",
    "\n",
    "        Args:\n",
    "            network: A PyTorch nn.Module constituting the deep neural network for mu and sigma.\n",
    "                      Output shape should be twice the channel size as the input.\n",
    "            mask: Binary mask (0 or 1) where 0 denotes that the element should be transformed,\n",
    "                   while 1 means the latent will be used as input to the NN.\n",
    "            c_in: Number of input channels\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.network = network\n",
    "        self.dim_notcond = dim_notcond\n",
    "        self.dim_cond = dim_cond\n",
    "        \n",
    "        self.net_notcond = network(int(self.dim_notcond / 2), int(self.dim_notcond), *network_args)\n",
    "        self.net_cond = network(self.dim_cond, int(self.dim_notcond), *network_args)\n",
    "        \n",
    "\n",
    "    def forward(self, z, x_condition, ldj, reverse=False, orig_img=None):\n",
    "        \"\"\"Forward.\n",
    "\n",
    "        Args:\n",
    "            z: Latent input to the flow\n",
    "            ldj:\n",
    "                The current ldj of the previous flows. The ldj of this layer will be added to this tensor.\n",
    "            reverse: If True, we apply the inverse of the layer.\n",
    "            orig_img:\n",
    "                Only needed in VarDeq. Allows external input to condition the flow on (e.g. original image)\n",
    "        \"\"\"\n",
    "        # Apply network to masked input\n",
    "        z_a, z_b = z.chunk(2, dim=1)\n",
    "       \n",
    "        s, t = (self.net_notcond(z_b) * self.net_cond(x_condition)).chunk(2, dim=1)\n",
    "\n",
    "        # Stabilize scaling output\n",
    "        s_fac = self.scaling_factor.exp().view(1, -1, 1, 1)\n",
    "        s = torch.tanh(s / s_fac) * s_fac\n",
    "\n",
    "        # Affine transformation\n",
    "        if not reverse:\n",
    "            # Whether we first shift and then scale, or the other way round,\n",
    "            # is a design choice, and usually does not have a big impact\n",
    "            z_a = (z_a + t) * torch.exp(s)\n",
    "            z_b = z_b\n",
    "            ldj += s.sum()\n",
    "            \n",
    "        else:\n",
    "            z_a = (z_a * torch.exp(-s)) - t\n",
    "            z_b = z_b\n",
    "            ldj -= s.sum()\n",
    "\n",
    "        return torch.cat([z_a, z_b]), ldj\n",
    "    \n",
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-layer perceptron (MLP) to be obtain parameters of Coupling layers\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_input : int \n",
    "        Number of input neurons, depend on the dimensions of the input data. \n",
    "    n_output : int \n",
    "        Number of output neurons, depend on the number of parameters needed for the Coupling layers.\n",
    "    n_hidden : int\n",
    "        Number of hidden neurons in each layer.\n",
    "    n_layers : int\n",
    "        Number of layers in the network.\n",
    "    neg_slope : float\n",
    "        Negative slope for the leaky ReLU activation function.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_input, n_output, n_hidden, n_layers=4, neg_slope=0.2) -> None:\n",
    "        super().__init__()\n",
    "        ins = torch.ones(n_layers)*n_hidden\n",
    "        ins[0] = n_input\n",
    "        outs = torch.ones(n_layers)*n_hidden\n",
    "        outs[-1] = n_output\n",
    "        Lin_layers = list(map(nn.Linear, ins.type(torch.int), outs.type(torch.int)))\n",
    "        ReLu_layers = [nn.LeakyReLU(neg_slope) for _ in range(n_layers)]\n",
    "        self.network = nn.Sequential(*itertools.chain(*zip(Lin_layers, ReLu_layers)))\n",
    "        # self.network.apply(init_weights)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "    \n",
    "class GLOW_conv(nn.Module):\n",
    "    def __init__(self, n_dim) -> None:\n",
    "        super().__init__()\n",
    "        self.n_dim = n_dim\n",
    "\n",
    "        #Initialize W as orthogonal matrix and decompose it into P, L, U, the learned parameters\n",
    "        W_initialize = nn.init.orthogonal_(torch.randn(self.n_dim, self.n_dim))\n",
    "        P, L_, U_ = torch.linalg.lu(W_initialize)\n",
    "\n",
    "        #P not changed (no grad) but it needs to be stored in the state_dict\n",
    "        self.register_buffer(\"P\", P)\n",
    "\n",
    "        # Declare as model parameters\n",
    "        #Diagonal of U sourced out to S\n",
    "        S_ = torch.diagonal(U_)\n",
    "        self.S = nn.Parameter(S_)\n",
    "        self.L = nn.Parameter(L_)\n",
    "        #Declare with diagonal 0s, without changing U_ and thus S_\n",
    "        self.U = nn.Parameter(torch.triu(U_, diagonal=1))\n",
    "\n",
    "    def _get_W_and_logdet(self):\n",
    "        #Make sure the pieces stay in correct shape as in GLOW\n",
    "        L = torch.tril(self.L, diagonal=-1) + torch.diag(torch.ones(self.n_dim).to(self.L.device))\n",
    "        U = torch.triu(self.U, diagonal=1)\n",
    "        S = torch.diag(self.S)\n",
    "        \n",
    "        W = self.P@L@(U+S)\n",
    "        logdetW = torch.sum(torch.log(torch.abs(self.S)))\n",
    "\n",
    "        return W, logdetW\n",
    "    \n",
    "    # Pass condition as extra argument, that is not used in the convolution\n",
    "    #it stayes untouched, does not get permuted with values that\n",
    "    #will be transformed\n",
    "    def forward(self, x, x_condition):\n",
    "        W, logdetW = self._get_W_and_logdet()\n",
    "        y = x.float()@W\n",
    "        return y, logdetW\n",
    "    \n",
    "    def backward(self, y, x_condition):\n",
    "        W, logdetW_inv = self._get_W_and_logdet()\n",
    "        #Just a minus needed\n",
    "        logdetW_inv = -logdetW_inv\n",
    "        W_inv = torch.linalg.inv(W)\n",
    "        x = y.float()@W_inv\n",
    "        return x, logdetW_inv\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_flow():\n",
    "    flow_model = ImageFlow(2, dim_notcond=2, dim_cond=12, import_samples=8).to(device)\n",
    "    return flow_model\n",
    "model = create_simple_flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_flow(flow, data:pd.DataFrame, cond_names:list, model_name=\"MNISTFlow\"):\n",
    "    # Create a PyTorch Lightning trainer\n",
    "    trainer = L.Trainer(\n",
    "        default_root_dir=os.path.join(CHECKPOINT_PATH, model_name),\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        max_epochs=10,\n",
    "        gradient_clip_val=1.0,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(save_weights_only=True, mode=\"min\", monitor=\"val_bpd\"),\n",
    "            LearningRateMonitor(\"epoch\"),\n",
    "        ],\n",
    "    )\n",
    "    trainer.logger._log_graph = True\n",
    "    trainer.logger._default_hp_metric = None  # Optional logging argument that we don't need\n",
    "\n",
    "    data = data[data.columns.difference(['Galaxy_name'])]\n",
    "\n",
    "    #Get index based masks for conditional variables\n",
    "    mask_cond = np.isin(data.columns.to_list(), cond_names)\n",
    "    mask_cond = torch.from_numpy(mask_cond).to(device)\n",
    "    \n",
    "    # Convert DataFrame to tensor (index based)\n",
    "    data = torch.from_numpy(data.values).type(torch.float)\n",
    "\n",
    "    train_data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True, num_workers=8)\n",
    "    \n",
    "    result = None\n",
    "\n",
    "    print(\"Start training\", model_name)\n",
    "    trainer.fit(flow, train_data_loader, val_loader)\n",
    "\n",
    "    # Test best model on validation and test set if no result has been found\n",
    "    # Testing can be expensive due to the importance sampling.\n",
    "    if result is None:\n",
    "        val_result = trainer.test(flow, dataloaders=val_loader, verbose=False)\n",
    "        start_time = time.time()\n",
    "        test_result = trainer.test(flow, dataloaders=test_loader, verbose=False)\n",
    "        duration = time.time() - start_time\n",
    "        result = {\"test\": test_result, \"val\": val_result, \"time\": duration / len(test_loader) / flow.import_samples}\n",
    "\n",
    "    return flow, result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
