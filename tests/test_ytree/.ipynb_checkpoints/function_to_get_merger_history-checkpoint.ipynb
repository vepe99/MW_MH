{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4e0936f-59f6-42f9-b06c-28841ccb4958",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ytree\n",
    "from tqdm import  tqdm\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c25c313b-2df4-498c-a82a-952df463a71f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional features and improved performance (usually) by saving this arbor with \"save_arbor\" and reloading:\n",
      "\t>>> a = ytree.load(\"../data/y_tree_data/ahf_halos/snap_N64L16_000.parameter\")\n",
      "\t>>> fn = a.save_arbor()\n",
      "\t>>> a = ytree.load(fn)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Planting trees: 100%|██████████████████████████████████████████████████████████████████████████████████| 136/136 [00:00<00:00, 164.42it/s]\n",
      "Getting fields [1 / ~1]: 100%|███████████████████████████████████████████████████████████████████████| 1937/1937 [00:04<00:00, 423.69it/s]\n",
      "yt : [INFO     ] 2023-09-30 18:45:11,984 Saving field data to yt dataset: arbor/arbor_0000.h5.\n",
      "yt : [INFO     ] 2023-09-30 18:45:12,031 Saving field data to yt dataset: arbor/arbor.h5.\n"
     ]
    }
   ],
   "source": [
    "a = ytree.load('../data/y_tree_data/ahf_halos/snap_N64L16_000.parameter')\n",
    "fn = a.save_arbor()\n",
    "a = ytree.load(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c991d6-b63c-4e35-a98e-3e7ee445d389",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Single merge implementation using list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b7e050-8e66-43ee-a88e-efc2dcf42394",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#arbor merger history extractor, it takes as input arbor = a[0]\n",
    "def get_arbor_merge_history_no_multiple_merger(arbor):\n",
    "    \n",
    "    #first we get the main progenitor of the arbor, this is in root -> leaves order\n",
    "    progenitor_root_to_leaves = list(arbor['prog'])\n",
    "\n",
    "    #we want the leaves -> root order for all of our data\n",
    "    progenitor_leaves_to_root = progenitor_root_to_leaves[::-1]\n",
    "    \n",
    "    #merge_history contains the pruned branch\n",
    "    merge_history = []\n",
    "    #progenitor_parallel_to_merge_history contains the element of the progenitor that are parallel to the merge_history\n",
    "    progenitor_parallel_to_merge_history = []\n",
    "   \n",
    "    #now we prune the arbor and keep the branch that are not the progenitor of the arbor, we will need the index i\n",
    "    for i in range( len(progenitor_leaves_to_root) ):\n",
    "        \n",
    "        #if the difference in the number of nodes bewteen two consecutive node in the progenitor_leaves_to_root is bigger than 1 it means that there is another branch:\n",
    "        l_i = len(list(progenitor_leaves_to_root[i]['tree']))\n",
    "        l_i_old = len(list(progenitor_leaves_to_root[i-1]['tree']))\n",
    "        if l_i - l_i_old > 1:\n",
    "                mh = [j for j in list(progenitor_leaves_to_root[i]['tree']) if j['uid'] not in list(progenitor_leaves_to_root[i-1]['tree', 'uid']) ]\n",
    "                \n",
    "                #f now is in root->leaves, we need to invert it to have leaves->root\n",
    "                merge_history.append(mh[::-1])\n",
    "                \n",
    "                #we take also the progenitor parallel to the merge_history branch mh that we are considering right now\n",
    "                ppmh = progenitor_leaves_to_root[i-len(mh):i]\n",
    "                progenitor_parallel_to_merge_history.append(ppmh)\n",
    "    \n",
    "    return merge_history, progenitor_parallel_to_merge_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae30ec2-d783-432a-a9f6-2aaa3142e732",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merge_history, progenitor_parallel_to_merge_history = get_arbor_merge_history_no_multiple_merger(a[0])\n",
    "\n",
    "for x in zip(merge_history[0], progenitor_parallel_to_merge_history[0]):\n",
    "    print(x, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bbe99e-0c13-4fd5-9c42-e96846c1ebee",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_history[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65af22f2-0f0e-4ca3-8954-c9e68e1a0449",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('merger_history_parallel_output.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db90361f-313a-462e-a693-b14ead427dc5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Multi merge implementation using dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55821d5-1a31-4d0e-9f41-2a0c936b958c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "di = {\n",
    "    'redshift': [1, 2]   \n",
    "}\n",
    "\n",
    "di['redshift'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1aa38d4-19bb-4fbb-8cf8-9a348ad51919",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "di_1 = {\n",
    "    'redshift': []\n",
    "}\n",
    "\n",
    "di_1['redshift'].append(1)\n",
    "\n",
    "di_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995e62c9-4e2b-466c-8214-89d58d9eb484",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "di_2 = {\n",
    "    1: [1,2],\n",
    "    2: [3, 4]\n",
    "}\n",
    "\n",
    "print(di_2[2])\n",
    "\n",
    "for i in di_2.keys():\n",
    "    print(di_2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3a2d1f-4916-4dc8-8f32-341059ced159",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "di_2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccff4ba-253b-4aac-89b3-443bde906288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "di_3 = {\n",
    " 1: {2: {3:[1,2]}}   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af69518-9b48-4b4a-8386-ddbfa6b8c6fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "di_3[1][2][1]={3:[2, 3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5544615-2711-46f9-a5d8-11287a4e4ebb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(di_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ec0609-ed43-40b9-abd6-8b3fd03af31e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "di_4 = {\n",
    "'event_number': {0:[],\n",
    "                 1:[]\n",
    "                }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad71c65-9b4e-4e61-9482-dc59d104e987",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "di_4['event_number'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7af209-1425-47c0-baea-beafe4f97385",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Multi merge implementation using Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee949eb8-7d8d-483e-af3e-f0d95f07465e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#arbor merger history extractor, it takes as input isolated Treenode like a[0] \n",
    "def get_arbor_merge_history(isolated_TreeNode):\n",
    "    \n",
    "    df = pd.DataFrame(columns = ['merge_index', 'redshift', 'merge_header', 'mass_merge_header', 'mass_progenitor_parallel_to_merge_header', 'merge_branch', 'progenitor_parallel_to_merge_branch'])\n",
    "\n",
    "    #first we get the main progenitor of the arbor, this is in root -> leaves order\n",
    "    progenitor_root_to_leaves = list(isolated_TreeNode['prog'])\n",
    "\n",
    "    #we want the leaves -> root order for all of our data\n",
    "    progenitor_leaves_to_root = progenitor_root_to_leaves[::-1]\n",
    "    \n",
    "   \n",
    "    merge_index = 0\n",
    "    #now we prune the arbor and keep the branch that are not the progenitor of the arbor, we will need the index i\n",
    "    for i in tqdm(range( len(progenitor_leaves_to_root)) ):\n",
    "        \n",
    "        #if the difference in the number of nodes bewteen two consecutive node in the progenitor_leaves_to_root is bigger than 1 it means that there is another branch:\n",
    "        l_i = progenitor_leaves_to_root[i].tree_size\n",
    "        l_i_old = progenitor_leaves_to_root[i-1].tree_size\n",
    "        if l_i - l_i_old > 1:\n",
    "            \n",
    "            pruned_branches = [j for j in progenitor_leaves_to_root[i]['tree'] if j['uid'] not in progenitor_leaves_to_root[i-1]['tree', 'uid'] ]\n",
    "            merge_header = [j for j in pruned_branches if j['redshift'] == progenitor_leaves_to_root[i-1]['redshift'] ]\n",
    "            for m_h in merge_header:\n",
    "                merge_branch = [j for j in pruned_branches if j['uid'] in m_h['tree', 'uid']]\n",
    "                redshift_merge_branch = [j['redshift'] for j in merge_branch]\n",
    "                  \n",
    "                progenitor_parallel_to_merge_branch = [j for j in progenitor_leaves_to_root[:i] if j['redshift'] <= max(redshift_merge_branch) and j['redshift'] >= min(redshift_merge_branch) ]\n",
    "                \n",
    "                df.loc[len(df)] = [merge_index, m_h['redshift'], merge_header, m_h['mass'], progenitor_leaves_to_root[i-1]['mass'], merge_branch[::-1], progenitor_parallel_to_merge_branch]\n",
    "                \n",
    "            merge_index += 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9637053d-a520-4a60-9fd1-0ee47296fea2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 114/114 [00:00<00:00, 665.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merge_index</th>\n",
       "      <th>redshift</th>\n",
       "      <th>merge_header</th>\n",
       "      <th>mass_merge_header</th>\n",
       "      <th>mass_progenitor_parallel_to_merge_header</th>\n",
       "      <th>merge_branch</th>\n",
       "      <th>progenitor_parallel_to_merge_branch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.875</td>\n",
       "      <td>[TreeNode[27609]]</td>\n",
       "      <td>64133100000.0 Msun/h</td>\n",
       "      <td>1272710000000.0 Msun/h</td>\n",
       "      <td>[TreeNode[28662], TreeNode[28539], TreeNode[28...</td>\n",
       "      <td>[TreeNode[28557], TreeNode[28436], TreeNode[28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.500</td>\n",
       "      <td>[TreeNode[24434]]</td>\n",
       "      <td>69661800000.0 Msun/h</td>\n",
       "      <td>1727170000000.0 Msun/h</td>\n",
       "      <td>[TreeNode[26592], TreeNode[26321], TreeNode[26...</td>\n",
       "      <td>[TreeNode[26372], TreeNode[26108], TreeNode[25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.400</td>\n",
       "      <td>[TreeNode[23741]]</td>\n",
       "      <td>72979000000.0 Msun/h</td>\n",
       "      <td>1836640000000.0 Msun/h</td>\n",
       "      <td>[TreeNode[26832], TreeNode[26584], TreeNode[26...</td>\n",
       "      <td>[TreeNode[26627], TreeNode[26372], TreeNode[26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.350</td>\n",
       "      <td>[TreeNode[23360]]</td>\n",
       "      <td>87353700000.0 Msun/h</td>\n",
       "      <td>1897450000000.0 Msun/h</td>\n",
       "      <td>[TreeNode[24077], TreeNode[23711], TreeNode[23...</td>\n",
       "      <td>[TreeNode[23878], TreeNode[23524], TreeNode[23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.300</td>\n",
       "      <td>[TreeNode[14847]]</td>\n",
       "      <td>622533000000.0 Msun/h</td>\n",
       "      <td>15166400000000.0 Msun/h</td>\n",
       "      <td>[TreeNode[20203], TreeNode[19807], TreeNode[19...</td>\n",
       "      <td>[TreeNode[20173], TreeNode[19776], TreeNode[19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.200</td>\n",
       "      <td>[TreeNode[13946]]</td>\n",
       "      <td>3242040000000.0 Msun/h</td>\n",
       "      <td>18113200000000.0 Msun/h</td>\n",
       "      <td>[TreeNode[26796], TreeNode[27717], TreeNode[27...</td>\n",
       "      <td>[TreeNode[27693], TreeNode[27504], TreeNode[27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.100</td>\n",
       "      <td>[TreeNode[13079]]</td>\n",
       "      <td>3371410000000.0 Msun/h</td>\n",
       "      <td>19354900000000.0 Msun/h</td>\n",
       "      <td>[TreeNode[13507], TreeNode[13079]]</td>\n",
       "      <td>[TreeNode[13502], TreeNode[13074]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.050</td>\n",
       "      <td>[TreeNode[12638]]</td>\n",
       "      <td>4024900000000.0 Msun/h</td>\n",
       "      <td>20057100000000.0 Msun/h</td>\n",
       "      <td>[TreeNode[19724], TreeNode[19312], TreeNode[18...</td>\n",
       "      <td>[TreeNode[26372], TreeNode[26108], TreeNode[25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[TreeNode[12198]]</td>\n",
       "      <td>3698710000000.0 Msun/h</td>\n",
       "      <td>19284200000000.0 Msun/h</td>\n",
       "      <td>[TreeNode[12639], TreeNode[12198]]</td>\n",
       "      <td>[TreeNode[12633], TreeNode[12192]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.900</td>\n",
       "      <td>[TreeNode[11615]]</td>\n",
       "      <td>95093900000.0 Msun/h</td>\n",
       "      <td>19970800000000.0 Msun/h</td>\n",
       "      <td>[TreeNode[22313], TreeNode[21929], TreeNode[21...</td>\n",
       "      <td>[TreeNode[22090], TreeNode[21712], TreeNode[21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.850</td>\n",
       "      <td>[TreeNode[10901]]</td>\n",
       "      <td>1402080000000.0 Msun/h</td>\n",
       "      <td>19628000000000.0 Msun/h</td>\n",
       "      <td>[TreeNode[14723], TreeNode[14309], TreeNode[13...</td>\n",
       "      <td>[TreeNode[14372], TreeNode[13940], TreeNode[13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.800</td>\n",
       "      <td>[TreeNode[10516]]</td>\n",
       "      <td>586044000000.0 Msun/h</td>\n",
       "      <td>19412400000000.0 Msun/h</td>\n",
       "      <td>[TreeNode[12379], TreeNode[11938], TreeNode[11...</td>\n",
       "      <td>[TreeNode[12192], TreeNode[11754], TreeNode[11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.750</td>\n",
       "      <td>[TreeNode[10130]]</td>\n",
       "      <td>336146000000.0 Msun/h</td>\n",
       "      <td>19597100000000.0 Msun/h</td>\n",
       "      <td>[TreeNode[17314], TreeNode[16892], TreeNode[16...</td>\n",
       "      <td>[TreeNode[29426], TreeNode[29398], TreeNode[29...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    merge_index  redshift       merge_header       mass_merge_header  \\\n",
       "0             0     3.875  [TreeNode[27609]]    64133100000.0 Msun/h   \n",
       "1             1     2.500  [TreeNode[24434]]    69661800000.0 Msun/h   \n",
       "2             2     2.400  [TreeNode[23741]]    72979000000.0 Msun/h   \n",
       "3             3     2.350  [TreeNode[23360]]    87353700000.0 Msun/h   \n",
       "4             4     1.300  [TreeNode[14847]]   622533000000.0 Msun/h   \n",
       "5             5     1.200  [TreeNode[13946]]  3242040000000.0 Msun/h   \n",
       "6             6     1.100  [TreeNode[13079]]  3371410000000.0 Msun/h   \n",
       "7             7     1.050  [TreeNode[12638]]  4024900000000.0 Msun/h   \n",
       "8             8     1.000  [TreeNode[12198]]  3698710000000.0 Msun/h   \n",
       "9             9     0.900  [TreeNode[11615]]    95093900000.0 Msun/h   \n",
       "10           10     0.850  [TreeNode[10901]]  1402080000000.0 Msun/h   \n",
       "11           11     0.800  [TreeNode[10516]]   586044000000.0 Msun/h   \n",
       "12           12     0.750  [TreeNode[10130]]   336146000000.0 Msun/h   \n",
       "\n",
       "   mass_progenitor_parallel_to_merge_header  \\\n",
       "0                    1272710000000.0 Msun/h   \n",
       "1                    1727170000000.0 Msun/h   \n",
       "2                    1836640000000.0 Msun/h   \n",
       "3                    1897450000000.0 Msun/h   \n",
       "4                   15166400000000.0 Msun/h   \n",
       "5                   18113200000000.0 Msun/h   \n",
       "6                   19354900000000.0 Msun/h   \n",
       "7                   20057100000000.0 Msun/h   \n",
       "8                   19284200000000.0 Msun/h   \n",
       "9                   19970800000000.0 Msun/h   \n",
       "10                  19628000000000.0 Msun/h   \n",
       "11                  19412400000000.0 Msun/h   \n",
       "12                  19597100000000.0 Msun/h   \n",
       "\n",
       "                                         merge_branch  \\\n",
       "0   [TreeNode[28662], TreeNode[28539], TreeNode[28...   \n",
       "1   [TreeNode[26592], TreeNode[26321], TreeNode[26...   \n",
       "2   [TreeNode[26832], TreeNode[26584], TreeNode[26...   \n",
       "3   [TreeNode[24077], TreeNode[23711], TreeNode[23...   \n",
       "4   [TreeNode[20203], TreeNode[19807], TreeNode[19...   \n",
       "5   [TreeNode[26796], TreeNode[27717], TreeNode[27...   \n",
       "6                  [TreeNode[13507], TreeNode[13079]]   \n",
       "7   [TreeNode[19724], TreeNode[19312], TreeNode[18...   \n",
       "8                  [TreeNode[12639], TreeNode[12198]]   \n",
       "9   [TreeNode[22313], TreeNode[21929], TreeNode[21...   \n",
       "10  [TreeNode[14723], TreeNode[14309], TreeNode[13...   \n",
       "11  [TreeNode[12379], TreeNode[11938], TreeNode[11...   \n",
       "12  [TreeNode[17314], TreeNode[16892], TreeNode[16...   \n",
       "\n",
       "                  progenitor_parallel_to_merge_branch  \n",
       "0   [TreeNode[28557], TreeNode[28436], TreeNode[28...  \n",
       "1   [TreeNode[26372], TreeNode[26108], TreeNode[25...  \n",
       "2   [TreeNode[26627], TreeNode[26372], TreeNode[26...  \n",
       "3   [TreeNode[23878], TreeNode[23524], TreeNode[23...  \n",
       "4   [TreeNode[20173], TreeNode[19776], TreeNode[19...  \n",
       "5   [TreeNode[27693], TreeNode[27504], TreeNode[27...  \n",
       "6                  [TreeNode[13502], TreeNode[13074]]  \n",
       "7   [TreeNode[26372], TreeNode[26108], TreeNode[25...  \n",
       "8                  [TreeNode[12633], TreeNode[12192]]  \n",
       "9   [TreeNode[22090], TreeNode[21712], TreeNode[21...  \n",
       "10  [TreeNode[14372], TreeNode[13940], TreeNode[13...  \n",
       "11  [TreeNode[12192], TreeNode[11754], TreeNode[11...  \n",
       "12  [TreeNode[29426], TreeNode[29398], TreeNode[29...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_history_df = get_arbor_merge_history(a[0])\n",
    "merge_history_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e62c17-f5cb-47f5-b0bd-a8cc3367ac7b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## If there are multiple merge_header at the same redshift shoul work, but it is not been tested yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c386bd7-1c09-45d9-a2c8-ebaf42e3ed63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p = ytree.TreePlot(a[1], dot_kwargs={'rankdir': 'LR', 'size':'\"12, 7\"'})\n",
    "p.save('same_redshift_merge.png')\n",
    "\n",
    "im = Image.open('same_redshift_merge.png')\n",
    "display(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32855581-4336-4108-9ba4-1cd3164f78e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## If there are merge_branch that are created by the merge of multiple halos\n",
    "It is possible to recover their structure, and plot by using iterativly `get_arbor_merge_history` to obtain another merger_history_df for the merger branch. It could be possible to use this procedure in a for loop on the merge branches for untill all the branch are analyzide and the merger_history_dfs are all empty (no more merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2815bbd5-ef73-4c4c-9272-51a826c6b484",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(13):\n",
    "    if len(merge_history_df.loc[i]['merge_branch']) == len(merge_history_df.loc[i]['progenitor_parallel_to_merge_branch']): \n",
    "        print(i, len(merge_history_df.loc[i]['merge_branch']), len(merge_history_df.loc[i]['progenitor_parallel_to_merge_branch']), 'the merging branch is made of one branch')\n",
    "    else:\n",
    "        print(i, len(merge_history_df.loc[i]['merge_branch']), len(merge_history_df.loc[i]['progenitor_parallel_to_merge_branch']), 'the merging branch is made of multiple converging branch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7393f04b-bac2-42de-89fa-d5809d4d7897",
   "metadata": {
    "tags": []
   },
   "source": [
    "### let's try with the 5th merging halo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a00d60b-590f-402f-b749-1e0d711fe4ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p = ytree.TreePlot(merge_history_df[merge_history_df['merge_index']==5]['merge_branch'].to_list()[0][-1],dot_kwargs={'rankdir': 'LR', 'size': '\"12,4\"'} )\n",
    "p.save('test_tree_merge_branch.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f497ebce-f5d9-4226-b7df-d8dfa4a6bab8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "im = Image.open('test_tree_merge_branch.png')\n",
    "display(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ae8c0c-606c-440d-960f-75bbbbebd97d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = get_arbor_merge_history(merge_history_df[merge_history_df['merge_index']==5]['merge_branch'].to_list()[0][-1])\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c82156-dec3-464c-bfd5-ff17779a0eb3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### let's try with the 7th merger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7b0d06-ede4-4c1b-bca6-e604ea0564b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p = ytree.TreePlot(merge_history_df[merge_history_df['merge_index']==7]['merge_branch'].to_list()[0][-1],dot_kwargs={'rankdir': 'LR', 'size': '\"12,4\"'} )\n",
    "p.save('test_tree_merge_branch.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced48ec9-22ef-4416-91e9-60b48aeb969b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "im = Image.open('test_tree_merge_branch.png')\n",
    "display(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b835ce-164b-4c20-89da-706b500bbb8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = get_arbor_merge_history(merge_history_df[merge_history_df['merge_index']==7]['merge_branch'].to_list()[0][-1])\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaa2606-dc0c-4c40-80e4-358d0a301144",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Analysis on the multi merge implementaion using Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8044303-2727-4772-902b-674188e50235",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mass_merger = []\n",
    "for i in range(len(merge_history_df)):\n",
    "    mass_merger.append(merge_history_df['mass_merge_header'][i])  \n",
    "plt.hist(mass_merger, 'sqrt');\n",
    "plt.xlabel(r'Merger_mass [M$_\\odot$] ')\n",
    "plt.grid(linestyle='dotted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab32f5f-3359-4b70-b05a-888c73ba7f7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#distance of the merger orbit is done only for single evolution branch, if the merger_branch is the result of multiple halo merge it needs \n",
    "#to be analyze separately (plotting the progenitor of the merge_branch maybe?')\n",
    "\n",
    "\n",
    "fig, ax =plt.subplots(1,1, figsize=(12,3))\n",
    "\n",
    "for j in range(len(merge_history_df)):\n",
    "    if j not in [5, 7, 12]:\n",
    "        r=[]\n",
    "        redshift = []\n",
    "        for i in range(len(merge_history_df['merge_branch'][j])):\n",
    "            mh = merge_history_df['merge_branch'][j][i]\n",
    "            pmh = merge_history_df['progenitor_parallel_to_merge_branch'][j][i]\n",
    "            r.append( np.sqrt( (mh['position_x']-pmh['position_x'])**2 + (mh['position_z']-pmh['position_y'])**2 + (mh['position_z']-pmh['position_z'])**2 ) )\n",
    "            redshift.append(mh['redshift'])\n",
    "        ax.plot(redshift, r, 'o--', label=f'merge event:{j}')\n",
    "ax.invert_xaxis()\n",
    "ax.grid(linestyle='dotted')\n",
    "ax.legend(bbox_to_anchor=(1.2, 1))\n",
    "ax.set_xlabel('redshift')\n",
    "ax.set_ylabel('Distance from progenitor [kpc]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4444192c-f0d6-4bd1-8bd3-0d39a24cbae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
